{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "#import dataiku\n",
    "from time import time, strftime\n",
    "import mysql.connector\n",
    "import unicodedata\n",
    "import MySQLdb\n",
    "from sqlalchemy import create_engine\n",
    "# import pandas.io.sql as psql\n",
    "import requests\n",
    "from datetime import date\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and Key (for MySql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_folder is the absolute path to the managed folder storing the data for the model\n",
    "data_folder = \"/\"\n",
    "\n",
    "# input on user\n",
    "features_df = json.loads(open('inputs_bouchons/user_infos.json').read())\n",
    "\n",
    "# Key\n",
    "# ssh -i privatekey.pem -L 3306:127.0.0.1:3306 ec2-user@52.31.201.94\n",
    "# Use .pem if unix else .ppk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get User Data Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "#################### Recuperation des donnees formulaires de lutilisateur ####################\n",
    "##############################################################################################\n",
    "\n",
    "def mapFeatureDF(features_df):\n",
    "    \"\"\" map features to user_info \"\"\"\n",
    "    return features_df['features']['userId'], features_df['features']['userInfos']\n",
    "\n",
    "\n",
    "def getUsersInfo(features_df):\n",
    "    \"\"\" Create a dataframe with all the user informations\"\"\"\n",
    "    sub_user_compl=mapFeatureDF(features_df)\n",
    "\n",
    "    # Mapping des donnees utilisateurs\n",
    "    user_info=pd.DataFrame(columns=['userId','adresse','dateOfBirth','familySituation','gender',\n",
    "                                    'magasinsPreferes','marchandsPreferes',\n",
    "                                    'transportPref','universConso','sensibilites'])\n",
    "    sub_user=sub_user_compl[1]\n",
    "\n",
    "    # Not filled\n",
    "    date_naiss=''\n",
    "    sit_fam=''\n",
    "    genr=''\n",
    "    adress=''\n",
    "    magP=''\n",
    "    marcP=''\n",
    "    transP=''\n",
    "    uniCo=''\n",
    "    sensB=''\n",
    "    try:\n",
    "        date_naiss=sub_user['dateDeNaissance']\n",
    "    except:\n",
    "        date_naiss=''\n",
    "    try:\n",
    "        sit_fam=sub_user['situationFamiliale']\n",
    "    except:\n",
    "        sit_fam=''\n",
    "    try:\n",
    "        genr=sub_user['genre']\n",
    "    except:\n",
    "        genr=''\n",
    "    try:\n",
    "        adress=sub_user['adresse']\n",
    "    except:\n",
    "        adress=''\n",
    "    try:\n",
    "        magP=sub_user['magasinsPreferes']\n",
    "    except:\n",
    "        magP=''\n",
    "    try:\n",
    "        marcP=sub_user['marchandsPreferes']\n",
    "    except:\n",
    "        marcP=''\n",
    "    try:\n",
    "        transP=sub_user['transport']\n",
    "    except:\n",
    "        transP=''\n",
    "    try:\n",
    "        uniCo=sub_user['universConso']\n",
    "    except:\n",
    "        uniCo=''\n",
    "    try:\n",
    "        sensB=sub_user['sensibilites']\n",
    "    except:\n",
    "        sensB=''\n",
    "\n",
    "    #print 'USer id :',sub_user_compl[0]\n",
    "    user_info.loc[0]=[sub_user_compl[0],adress,date_naiss,sit_fam,genr,\n",
    "                      magP,marcP,transP,uniCo,\n",
    "                      sensB]\n",
    "\n",
    "    return user_info\n",
    "\n",
    "def completionUserInfos(user_info,list_user):\n",
    "    # Simplification and completion of the user infos : add sensibilities\n",
    "    for idx,i in enumerate(user_info['sensibilites']):\n",
    "        bioS=[]\n",
    "        prixS=[]\n",
    "        reducS=[]\n",
    "        for y in range(len(i)):\n",
    "            if i[y]['prix']:\n",
    "                prixS.append(i[y]['idCateg'])\n",
    "            if i[y]['reduction']:\n",
    "                reducS.append(i[y]['idCateg'])\n",
    "            if i[y]['ecologie']:\n",
    "                bioS.append(i[y]['idCateg'])\n",
    "\n",
    "        user_info.loc[idx,'analyticsprixSens']=str(prixS)\n",
    "        user_info.loc[idx,'analyticsreductionSens']=str(reducS)\n",
    "        user_info.loc[idx,'analyticsbioSens']=str(bioS)\n",
    "\n",
    "    # Univers Conso\n",
    "    for udx,u in enumerate(user_info['universConso']):\n",
    "        univC=[]\n",
    "        for w in range(len(u)):\n",
    "            univC.append(u[w]['id'])\n",
    "\n",
    "\n",
    "        user_info.loc[udx,'analyticsuniversConso']=str(univC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add external informations about INSEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "############################# Add external informations about INSEE ##########################\n",
    "############################################################################################## \n",
    "\n",
    "def getCodeInseeFromAdress(df):\n",
    "    \"\"\" Use api adresse from french ministery to find the code insee of the city\"\"\"\n",
    "    adress=df['adresse'][0]['rue']+' '+df['adresse'][0]['codePostal']+' '+df['adresse'][0]['commune']\n",
    "    str1=\"http://api-adresse.data.gouv.fr/reverse/?lon=\"+lon+\"&lat=\"+lat\n",
    "    str2 = requests.get(str1).json()\n",
    "    return str2['features'][0]['properties']['citycode']\n",
    "\n",
    "def getCodeInseeFromLatLong(df):\n",
    "    \"\"\" Use api adresse from french ministery to find the code insee of the city\"\"\"\n",
    "    lat, lon=df['adresse'][0]['position'].split(',')\n",
    "    str1=\"http://api-adresse.data.gouv.fr/reverse/?lon=\"+lon+\"&lat=\"+lat\n",
    "    str2 = requests.get(str1).json()\n",
    "    return str2['features'][0]['properties']['citycode']\n",
    "\n",
    "def getCityInformations(df):\n",
    "    # Get Code INSEE\n",
    "    cod_insee=getCodeInseeFromLatLong(df)\n",
    "    # Get infos into the database\n",
    "    conn= mysql.connector.connect(host='localhost',database='dataiku',user='dkuadmin',password='Dataiku!')\n",
    "    req = \"SELECT * from insee_data where CODGEO=\\'\"+cod_insee+\"\\'\"\n",
    "    insee_data = pd.read_sql(req, conn)\n",
    "    return insee_data['CATAEU2010']\n",
    "\n",
    "def ruleZoneUrbZonrRur(cataeu):\n",
    "    result='ZRur'\n",
    "    if cataeu[0][0]=='1':\n",
    "        result='ZUrb'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appetance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "####################### Creation de la matrice appetance de lutilisateur #####################\n",
    "##############################################################################################        \n",
    "\n",
    "def matrixProductColumnsAndMajProducts(list_user,list_cat):\n",
    "    list_index=[]\n",
    "    for i in list_user:\n",
    "        for ii in list_cat.keys():\n",
    "            if i=='prixSens':\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_highPrice')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_lowPrice')\n",
    "\n",
    "            elif i=='reductionSens':\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_noreduc')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_freeImm')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_2iemGrat')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_3iemGrat')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_carte')\n",
    "                list_index.append(str(i)+'_'+str(ii)+'_autres')\n",
    "\n",
    "            else:\n",
    "                list_index.append(str(i)+'_'+str(ii))\n",
    "\n",
    "    list_index.append('quantity_unit')\n",
    "    list_index.append('quantity_family')\n",
    "    list_index.append('travelTime')\n",
    "    list_index.append('mag_Fnac')\n",
    "    list_index.append('mag_Carrefour')\n",
    "    list_index.append('mag_Monoprix')\n",
    "    list_index.append('mag_Autres')\n",
    "\n",
    "    return list_index\n",
    "\n",
    "def matrixUser(list_index):\n",
    "    # User matrix\n",
    "    return pd.Series(0.00,index=list_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Ponderation infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "######################## Recuperation des pondérations des champs ##########################\n",
    "##############################################################################################\n",
    "\n",
    "### Dictionnaire de ponderation des modeles\n",
    "def getDictPond():\n",
    "    conn= mysql.connector.connect(host='localhost',database='dataiku',user='dkuadmin',password='Dataiku!')\n",
    "    req = \"SELECT * from ponduserinformations order by date desc limit 1\"\n",
    "    pond_df = pd.read_sql(req, conn)\n",
    "    pond_df_temp=pond_df.to_dict(orient='list')\n",
    "    return {k:v[0] for (k,v) in pond_df_temp.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "################################### Notation de lutilisateur #################################\n",
    "##############################################################################################\n",
    "\n",
    "def enrichDataUser(serie,df_user,list_cat,pondCol):\n",
    "    \"\"\"Enrichissement des donnees des utilisateurs pour quils correspondent avec la matrice produit. Integration des ponderations de colonnes\n",
    "\n",
    "    Args:\n",
    "        serie: matrice avec les donnees utilisateur\n",
    "        df_user: dataframe avec les donnees utilisateur\n",
    "        pondCol : poids des categories de colonnes\n",
    "\n",
    "    Returns:\n",
    "        mise a jour de la matrice avec les produits\n",
    "    \"\"\"\n",
    "    # Liste categories produits alimentaires\n",
    "    list_alim=['2000','2001','2002','2003','2004','2005','2006','2007','2008','2009','2010','2011','2012']\n",
    "\n",
    "    # Informations about the user\n",
    "    score_marchand_pref=1\n",
    "    score_gamme_high=0\n",
    "    score_gamme_low=1\n",
    "    # Rules if the user lives in a rural area : TO BE COMPLETED\n",
    "    if df_user['CATAEU'][0]=='ZUrb':\n",
    "        score_quantity=1\n",
    "        score_temp_trajet=1\n",
    "    else:\n",
    "        score_quantity=0.1\n",
    "        score_temp_trajet=1\n",
    "    score_bio=1\n",
    "    score_reduc_noreduc=0\n",
    "    score_reduc_freeImm=1\n",
    "    score_reduc_2iemGrat=1\n",
    "    score_reduc_3iemGrat=1\n",
    "    score_reduc_carte=1\n",
    "    score_reduc_autres=1\n",
    "    score_univ_conso=1\n",
    "\n",
    "    serie['user_id']=df_user['userId'][0]\n",
    "\n",
    "    serie['quantity_unit']=score_quantity\n",
    "    serie['quantity_family']=score_quantity\n",
    "    # Travel time\n",
    "    serie['travelTime']=score_temp_trajet\n",
    "    # Univers conso\n",
    "    if len(df_user['analyticsuniversConso'][0])-2>0:\n",
    "        list_univ=addAllAlim(df_user['analyticsuniversConso'][0],list_alim)\n",
    "        for i in list_univ:\n",
    "            serie['universConso_'+str(i)]=score_univ_conso*float(pondCol['univers_conso'])\n",
    "    # Bio sens\n",
    "    if len(df_user['analyticsbioSens'][0])-2>0:\n",
    "        list_bio=addAllAlim(df_user['analyticsbioSens'][0],list_alim)\n",
    "        for i in list_bio:\n",
    "            serie['bioSens_'+str(i)]=score_bio*float(pondCol['weight_ecolo'])\n",
    "    # Reduction sens\n",
    "    if len(df_user['analyticsreductionSens'][0])-2>0:\n",
    "\n",
    "        list_reduc=addAllAlim(df_user['analyticsreductionSens'][0],list_alim)\n",
    "        for i in list_reduc:\n",
    "            serie['reductionSens_'+str(i)+'_noreduc']=score_reduc_noreduc*float(pondCol['weight_reduc'])\n",
    "            serie['reductionSens_'+str(i)+'_freeImm']=score_reduc_freeImm*float(pondCol['weight_reduc'])\n",
    "            serie['reductionSens_'+str(i)+'_2iemGrat']=score_reduc_2iemGrat*float(pondCol['weight_reduc'])\n",
    "            serie['reductionSens_'+str(i)+'_3iemGrat']=score_reduc_3iemGrat*float(pondCol['weight_reduc'])\n",
    "            serie['reductionSens_'+str(i)+'_carte']=score_reduc_carte*float(pondCol['weight_reduc'])\n",
    "            serie['reductionSens_'+str(i)+'_autres']=score_reduc_autres*float(pondCol['weight_reduc'])\n",
    "    # Prix sens\n",
    "    if len(df_user['analyticsprixSens'][0])-2>0:       \n",
    "        list_prix=addAllAlim(df_user['analyticsprixSens'][0],list_alim)\n",
    "        for i in list_prix:\n",
    "            serie['prixSens_'+str(i)+'_lowPrice']=score_gamme_low*float(pondCol['weight_prix'])\n",
    "        #for i in list_cat.keys():\n",
    "            #if i not in list_prix:\n",
    "                #serie['prixSens_'+str(i)+'_lowPrice']=score_gamme_low\n",
    "    # Magasin\n",
    "    list_march=df_user['marchandsPreferes']\n",
    "    if len(list_march)>0:\n",
    "        for i in list_march[0]:\n",
    "            if 'monop' in i['nom'].lower():\n",
    "                    serie['mag_Monoprix']=1*float(pondCol['weight_marque'])\n",
    "            if 'fnac' in i['nom'].lower():\n",
    "                serie['mag_Fnac']=1*float(pondCol['weight_marque'])\n",
    "            if 'carrefour' in i['nom'].lower():\n",
    "                serie['mag_Carrefour']=1*float(pondCol['weight_marque'])\n",
    "            if 'fnac' not in i['nom'].lower() and 'monop' not in i['nom'].lower() and 'carrefour' not in i['nom'].lower():\n",
    "                serie['mag_Autres']=1*float(pondCol['weight_marque'])\n",
    "\n",
    "    # Age, Sexe, Gender, Situation and Zone\n",
    "    serie['age']=fromDobToAge(df_user)\n",
    "    serie['sexe']=fromGenderToClean(df_user)\n",
    "    serie['situation']=fromSituationToClean(df_user)\n",
    "    serie['zone']=df_user['CATAEU'][0]\n",
    "\n",
    "\n",
    "### Add all under categories of alimentation if global alimentation 1000 is checked            \n",
    "def addAllAlim(list_ini,list_alim):\n",
    "    li=strToList(list_ini)\n",
    "    result=li\n",
    "    if '1000' in li:\n",
    "        result.extend(list_alim)\n",
    "    return result\n",
    "\n",
    "### Convert string list to list with unicode treatment\n",
    "def strToList(stri):\n",
    "    return stri.replace('u','').replace('\\'','').replace(' ','').replace('[','').replace(']','').split(',')\n",
    "\n",
    "### From date of birth to age\n",
    "def fromDobToAge(df_user):\n",
    "    dob=df_user['dateOfBirth'][0]\n",
    "    try:\n",
    "        age=date.today().year-int(dob[:4])\n",
    "        result=4\n",
    "        if age<20:\n",
    "            result=1\n",
    "        elif age<30:\n",
    "            result=2\n",
    "        elif age<50:\n",
    "            result=3\n",
    "    except:\n",
    "        result=0\n",
    "    return result\n",
    "\n",
    "### From genre to our format Homme:1, Femme:2, adefinir:0\n",
    "def fromGenderToClean(df_user):\n",
    "    # Homme, Femme, else\n",
    "    gender=df_user['gender'][0]\n",
    "    result=0\n",
    "    if gender=='Homme':\n",
    "        result=1\n",
    "    elif gender=='Femme':\n",
    "        result=2\n",
    "    return result\n",
    "\n",
    "### From situation to our format Célibataire:1, En couple sans enfant:2, En couple avec enfant(s):3, adefinir:0\n",
    "def fromSituationToClean(df_user):\n",
    "    # Célibataire, En couple sans enfant, En couple avec enfant(s), else\n",
    "    situation=df_user['familySituation'][0]\n",
    "    result=0\n",
    "    if situation=='Célibataire':\n",
    "        result=1\n",
    "    elif situation=='En couple sans enfant':\n",
    "        result=2\n",
    "    elif situation=='En couple avec enfant(s)':\n",
    "        result=3\n",
    "    return result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "################################ Sauvegarde des donnees en base ##############################\n",
    "##############################################################################################\n",
    "\n",
    "## Connecteur mysql update\n",
    "\n",
    "def saveUserMatrix(df_tosave,table_name,user_id):\n",
    "    df_to_save=pd.DataFrame({user_id:df_tosave}).transpose()\n",
    "    list_col_notzero=[]\n",
    "    for i in df_to_save.columns:\n",
    "        if df_to_save.ix[0,i]>0:\n",
    "            list_col_notzero.append(i)\n",
    "    #print df_to_save[list_col_notzero]\n",
    "\n",
    "    #output_ds.write_from_dataframe(df_to_save)\n",
    "\n",
    "    time_msql=time()\n",
    "    # Connecting to DB\n",
    "    #time_connect_db=time()\n",
    "    conn= mysql.connector.connect(host='localhost',database='dataiku',user='dkuadmin',password='Dataiku!')\n",
    "    #print 'Time to connect to DB :', time()-time_connect_db\n",
    "\n",
    "    # Remove user infos\n",
    "    cursor=conn.cursor()\n",
    "    req = \"DELETE FROM userinformations where user_id=\\'\"+user_id+\"\\'\"\n",
    "    #pd.read_sql(req, conn)\n",
    "    cursor.execute(req)\n",
    "    conn.commit()\n",
    "\n",
    "    # Insert user info\n",
    "    engine = create_engine('mysql+mysqlconnector://dkuadmin:Dataiku!@localhost:3306/dataiku', echo=False)\n",
    "    df_to_save.to_sql('userinformations', engine, if_exists='append',index=False)\n",
    "\n",
    "    print 'Time mysql :',time()-time_msql\n",
    "\n",
    "    #conn= mysql.connector.connect(host='localhost',database='dataiku',user='dkuadmin',password='maverick')\n",
    "    #req = \"SELECT * from userinformations\"\n",
    "    #couponscores = pd.read_sql(req, conn)\n",
    "    #print couponscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################\n",
    "##################################### Prediction ou calcul ###################################\n",
    "##############################################################################################    \n",
    "\n",
    "def predict(features_df):\n",
    "    \"\"\"\n",
    "    The main prediction method.\n",
    "\n",
    "    :param: df: a dataframe of 1 or several records to predict\n",
    "\n",
    "    :return: Either:\n",
    "        ``decision_series`` or\n",
    "        ``(decision_series, proba_df)`` or\n",
    "        ``(decision_series, proba_df, custom_keys_list)``\n",
    "\n",
    "    decision_series must be a Pandas Series of decisions\n",
    "\n",
    "    proba_df is optional and must contain one column per class\n",
    "\n",
    "    custom_keys_list is optional and must contain one entry per input row. Each entry of\n",
    "    custom_keys_list must be a Python dictionary. These custom keys will be sent in the\n",
    "    output result\n",
    "\n",
    "    decision_series, proba_df and custom_keys_list must have the same number of rows than df.\n",
    "    It is legal to refuse to score a record. Leave a NA in decision_series\n",
    "    \"\"\"\n",
    "\n",
    "    # Note: this sample uses the second form (decision_series, proba_df)\n",
    "\n",
    "    # Note: this sample \"cheats\" and always returns 5 predictions.\n",
    "    # You should actually return 1 prediction per row in the features_df\n",
    "\n",
    "    time_start=time()\n",
    "\n",
    "    #print \"Features DataFrame %s\" % features_df\n",
    "\n",
    "    list_user=['universConso','bioSens','prixSens','reductionSens']\n",
    "\n",
    "    # Get ponderation\n",
    "    pondCol=getDictPond()\n",
    "\n",
    "    # Get user infos\n",
    "    time_firststep=time()\n",
    "    user_info=getUsersInfo(features_df)\n",
    "    completionUserInfos(user_info,list_user)\n",
    "    if len(user_info['adresse'][0])>1:\n",
    "        user_info['CATAEU']= ruleZoneUrbZonrRur(getCityInformations(user_info))\n",
    "    else :\n",
    "        user_info['CATAEU']=\"\"\n",
    "    print 'Time get user info step 1 : ', time()-time_firststep\n",
    "\n",
    "\n",
    "    product_info=pd.DataFrame()\n",
    "    list_cat={'1000':'Alimentation','1001':'Puericulture et Enfants','1002':'Equipements de la maison et High-Tech',\n",
    "              '1003':'Sports, Loisirs et Culture','1004':'Bricolage, Decoration, Jardinerie et Animalerie',\n",
    "              '1005':'Mode et Accessoires','1006':'Auto et Moto','1007':'Beaute Sante et Bien-etre',\n",
    "              '1008':'Hotel Restaurant et Cafes','1009':'Banques et Assurances','1010':'Voyages et transports',\n",
    "              '1011':'Services',\n",
    "              '2000':'Bebe','2001':'Boissons','2002':'Boucherie','2003':'Boulangerie','2004':'Charcuterie et Traiteur',\n",
    "              '2005':'Cremerie','2006':'Epicerie salee','2007':'Epicerie sucree','2008':'Fruits frais','2009':'Legumes frais',\n",
    "              '2010':'Produits de la mer','2011':'Produits dietetiques','2012':'Surgeles'}\n",
    "    list_index=matrixProductColumnsAndMajProducts(list_user,list_cat)\n",
    "    matrix_user=matrixUser(list_index)\n",
    "\n",
    "    # Enrich user data\n",
    "    time_enrichUser=time()\n",
    "    enrichDataUser(matrix_user,user_info,list_cat,pondCol)\n",
    "    print 'Time enrich user data : ',time()-time_enrichUser\n",
    "\n",
    "    # Saving user info\n",
    "    time_save=time()\n",
    "    #print matrix_user\n",
    "    saveUserMatrix(matrix_user,'userinformations',features_df['features']['userId'])\n",
    "    print 'Time saving user infos : ', time()-time_save\n",
    "\n",
    "    print 'Temps traitement total CPI USER : ', time()-time_start\n",
    "    return 'User informations has been saved into  userinformations : ', user_info['userId'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time get user info step 1 :  0.228134870529\n",
      "Time enrich user data :  0.00715208053589\n",
      "Time mysql : 1.1366751194\n",
      "Time saving user infos :  1.21205306053\n",
      "Temps traitement total CPI USER :  1.60635304451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('User informations has been saved into  userinformations : ', 0    user1\n",
       " Name: userId, dtype: object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
